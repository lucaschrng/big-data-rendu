# ğŸ“Š Data Lake Analytics Project

Architecture Bronze-Silver-Gold avec pipeline ELT complet et dashboard Streamlit.

## ğŸ—ï¸ Architecture

```
Sources â†’ Bronze â†’ Silver â†’ Gold â†’ Dashboard
         (Raw)   (Clean)  (Business)  (Viz)
```

### Couches de donnÃ©es

- **Bronze**: DonnÃ©es brutes, copie fidÃ¨le des sources
- **Silver**: DonnÃ©es nettoyÃ©es, validÃ©es et standardisÃ©es
- **Gold**: AgrÃ©gations mÃ©tier, KPIs et mÃ©triques business

## ğŸš€ Quick Start

### 1. Installation

```bash
# Installer les dÃ©pendances
uv sync
```

### 2. DÃ©marrer l'infrastructure

```bash
# Lancer MinIO et Prefect
docker-compose up -d

# VÃ©rifier que les services sont actifs
docker-compose ps
```

**Services disponibles:**
- MinIO Console: http://localhost:9001 (minioadmin / minioadmin)
- Prefect UI: http://localhost:4200

### 3. GÃ©nÃ©rer les donnÃ©es (optionnel)

```bash
# GÃ©nÃ©rer de nouvelles donnÃ©es de test
python script/generate_data.py
```

### 4. ExÃ©cuter le pipeline ELT

```bash
# Pipeline complet (Bronze â†’ Silver â†’ Gold)
cd flows
python run_pipeline.py
```

### 5. Lancer le dashboard

```bash
# DÃ©marrer Streamlit
streamlit run dashboard.py
```

Le dashboard sera accessible sur http://localhost:8501

## ğŸ“Š Dashboard Streamlit

Le dashboard contient 6 pages:

### ğŸ  Overview
- KPIs principaux (revenus, commandes, clients)
- Segmentation clients (actifs/inactifs, high-value)
- Top performers (produit, pays, client)
- Tendances rÃ©centes (30 derniers jours)

### ğŸ“ˆ Temporal Analysis
- Analyse quotidienne, hebdomadaire ou mensuelle
- Graphiques de tendance des revenus
- Taux de croissance pÃ©riode Ã  pÃ©riode
- Moyennes mobiles (7 jours)

### ğŸ‘¥ Client Analytics
- Analyse RFM (Recency, Frequency, Monetary)
- Distribution des clients par segment
- Top 10 clients par dÃ©penses
- Lifetime value et frÃ©quence d'achat

### ğŸ“¦ Product Analytics
- Revenus par produit
- Parts de marchÃ©
- Analyse des prix (min, max, moyenne)
- Clients uniques par produit

### ğŸŒ Geographic Analysis
- Revenus par pays
- Parts de marchÃ© gÃ©ographiques
- Panier moyen par pays
- Nombre de clients par pays

### ğŸ“Š Statistics
- Distributions statistiques complÃ¨tes
- Box plots et percentiles
- MÃ©triques globales
- Statistiques descriptives

## âš¡ Apache Spark (Big Data)

### DÃ©marrer le cluster Spark

```bash
# Lancer le cluster complet (1 master + 2 workers)
docker-compose up -d spark-master spark-worker-1 spark-worker-2

# VÃ©rifier le cluster
docker-compose ps
```

**Spark UI disponible sur:** http://localhost:8080

### ExÃ©cuter le pipeline Spark

```bash
cd flows

# Pipeline Spark uniquement
python spark_silver_transformation.py
python spark_gold_aggregation.py

# Ou utiliser le benchmark pour comparer Pandas vs Spark
python benchmark.py
```

### Benchmark Pandas vs Spark

```bash
cd flows

# Benchmark complet (Pandas + Spark)
python benchmark.py

# Options disponibles
python benchmark.py --pandas-only     # Seulement Pandas
python benchmark.py --spark-only      # Seulement Spark
python benchmark.py --spark-master spark://spark-master:7077  # Cluster distant

# Les rÃ©sultats sont sauvegardÃ©s dans data/benchmark_results.json
```

#### Exemple de sortie benchmark

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        TIMING COMPARISON (seconds)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Step                  â”‚ Pandas            â”‚ Spark             â”‚ Speedup     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Bronze Ingestion      â”‚            0.1234 â”‚            0.0000 â”‚         N/A â”‚
â”‚ Silver Transformation â”‚            0.2345 â”‚            1.5678 â”‚       0.15x â”‚
â”‚ Gold Aggregation      â”‚            0.3456 â”‚            2.3456 â”‚       0.15x â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL                 â”‚            0.7035 â”‚            3.9134 â”‚       0.18x â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ† Winner: PANDAS
   Reason: Lower overhead for small datasets
```

> **ğŸ’¡ Note**: Spark a un overhead de dÃ©marrage. Avec des datasets plus volumineux (millions de lignes), Spark montrera des gains de performance significatifs grÃ¢ce au traitement distribuÃ©.

## ğŸš€ Base NoSQL & Dashboarding (Nouveau)

Une couche opÃ©rationnelle temps-rÃ©el a Ã©tÃ© ajoutÃ©e :

1.  **MongoDB** : Base NoSQL pour les donnÃ©es Gold (Lecture rapide).
2.  **FastAPI** : API REST exposant les KPIs et donnÃ©es analytiques.
3.  **Streamlit** : Dashboard interactif consommant l'API.
4.  **Metabase** : Outil BI open-source pour l'exploration de donnÃ©es.

### ğŸ”„ Pipeline de RafraÃ®chissement

Pour gÃ©nÃ©rer les donnÃ©es Gold (Parquet) et les charger dans MongoDB :

```bash
uv run flows/benchmark_refresh.py
```
*Temps de refresh moyen : ~6 secondes*

### ğŸŒ Lancer l'API et le Dashboard

1.  **DÃ©marrer l'API** (Port 8000) :
    ```bash
    uv run uvicorn api.main:app --reload --port 8000
    ```

2.  **DÃ©marrer le Dashboard UnifiÃ©** (Port 8501) :
    ```bash
    uv run streamlit run dashboard.py
    ```

    > **Nouveau** : Le dashboard possÃ¨de maintenant un sÃ©lecteur de source de donnÃ©es dans la barre latÃ©rale :
    > - **Data Lake (Historical/MinIO)** : Visualisation des fichiers statiques (CSV/Parquet) du bucket Gold.
    > - **Operational (Live/MongoDB)** : Visualisation temps-rÃ©el via l'API FastAPI et MongoDB.

### ğŸ“Š AccÃ¨s Ã  Metabase

Metabase est disponible sur [http://localhost:3000](http://localhost:3000).
- **Setup** : Suivez l'assistant d'installation.
- **Connexion BDD** :
    - Type : PostgreSQL
    - Host : `postgres`
    - Port : `5432`
    - Database : `prefect` (ou autre si configurÃ©)
    - User/Pass : `prefect` / `prefect`

## ğŸ“Š RÃ©sultats du Benchmark (OptimisÃ©)

Sur un MacBook Pro (M1/M2/M3) avec le dataset par dÃ©faut (2M clients, 10M achats) :

| Ã‰tape | Pandas (Local) | Spark (Local OptimisÃ©) |
|-------|---------------:|------------------------|
| Ingestion Bronze | ~14s | N/A (PartagÃ©) |
| Transformation Silver | ~42s | ~76s |
| AgrÃ©gation Gold | ~91s | ~176s |
| **Total** | **~147s** | **~252s** |

### ğŸ’¡ Analyse des Performances

1.  **Pourquoi Pandas est plus rapide ici ?**
    *   Le dataset (12M lignes) tient entiÃ¨rement en RAM.
    *   Pandas n'a pas l'overhead de dÃ©marrage de JVM/Spark (1-2s par job).
    *   Les opÃ©rations se font "in-memory" sans sÃ©rialisation/dÃ©sÃ©rialisation complexe.

2.  **Quand utiliser Spark ?**
    *   Si le dataset dÃ©passe la RAM (ex: > 100M lignes ou > 50GB).
    *   Si les calculs nÃ©cessitent un cluster distribuÃ© (plusieurs machines).
    *   Pour des jointures complexes sur des donnÃ©es massives.

3.  **Optimisations Spark appliquÃ©es :**
    *   **Broadcast Joins** pour les tables de dimension (Clients).
    *   **Partitioning** intelligent (8 partitions en local).
    *   Suppression des actions `.count()` inutiles (Lazy Evaluation).
    *   **Coalesce(1)** pour les agrÃ©gations globales (petits rÃ©sultats).

## ğŸ› ï¸ Stack Technique

### Infrastructure
- **MinIO**: Stockage objet (data lake)
- **PostgreSQL**: Base de donnÃ©es Prefect
- **Prefect**: Orchestration des workflows
- **Apache Spark**: Traitement distribuÃ© Big Data (1 master + 2 workers)

### Python
- **Pandas**: Manipulation de donnÃ©es (single-node)
- **PySpark**: Manipulation de donnÃ©es distribuÃ©e
- **Prefect**: Orchestration
- **Streamlit**: Dashboard interactif
- **Plotly**: Visualisations

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ data/                       # DonnÃ©es sources (CSV)
â”‚   â”œâ”€â”€ clients.csv
â”‚   â””â”€â”€ purchases.csv
â”œâ”€â”€ flows/                      # Flows Prefect
â”‚   â”œâ”€â”€ config.py              # Configuration MinIO/Prefect
â”‚   â”œâ”€â”€ bronze_ingestion.py    # Ingestion Bronze
â”‚   â”œâ”€â”€ silver_transformation.py # Transformation Silver (Pandas)
â”‚   â”œâ”€â”€ gold_aggregation.py    # AgrÃ©gation Gold (Pandas)
â”‚   â”œâ”€â”€ spark_silver_transformation.py # Transformation Silver (Spark)
â”‚   â”œâ”€â”€ spark_gold_aggregation.py # AgrÃ©gation Gold (Spark)
â”‚   â”œâ”€â”€ benchmark.py           # Benchmark Pandas vs Spark
â”‚   â””â”€â”€ run_pipeline.py        # Pipeline complet
â”œâ”€â”€ script/
â”‚   â””â”€â”€ generate_data.py       # GÃ©nÃ©ration de donnÃ©es
â”œâ”€â”€ dashboard.py               # Dashboard Streamlit
â”œâ”€â”€ docker-compose.yml         # Infrastructure
â”œâ”€â”€ pyproject.toml            # DÃ©pendances
â””â”€â”€ README.md
```

## ğŸ“¦ Buckets MinIO

### sources/
- Fichiers sources temporaires
- Point d'entrÃ©e des donnÃ©es

### bronze/
- DonnÃ©es brutes archivÃ©es
- Source of truth immuable

### silver/
- DonnÃ©es nettoyÃ©es et validÃ©es
- `clients.csv`: Clients validÃ©s
- `purchases.csv`: Achats validÃ©s
- `quality_report.json`: Rapport de qualitÃ©

### gold/
- DonnÃ©es agrÃ©gÃ©es et KPIs
- `fact_sales.csv`: Table de faits
- `client_kpis.csv`: KPIs clients
- `product_analytics.csv`: Analytics produits
- `country_analytics.csv`: Analytics pays
- `daily_sales.csv`: AgrÃ©gations quotidiennes
- `weekly_sales.csv`: AgrÃ©gations hebdomadaires
- `monthly_sales.csv`: AgrÃ©gations mensuelles
- `statistical_distributions.json`: Statistiques
- `gold_summary.json`: RÃ©sumÃ© exÃ©cutif

## ğŸ”„ Workflows

### Bronze Ingestion
```bash
cd flows
python bronze_ingestion.py
```
- Upload des CSV vers MinIO sources
- Copie vers la couche Bronze

### Silver Transformation
```bash
cd flows
python silver_transformation.py
```
- Nettoyage des valeurs nulles
- Standardisation des dates
- Validation des donnÃ©es
- DÃ©duplication
- GÃ©nÃ©ration du rapport de qualitÃ©

### Gold Aggregation
```bash
cd flows
python gold_aggregation.py
```
- CrÃ©ation de la fact table
- Calcul des KPIs clients
- Analytics produits et pays
- AgrÃ©gations temporelles
- Statistiques descriptives

## ğŸ“Š KPIs disponibles

### Clients
- Total spent, average order value
- Purchase frequency
- Customer lifetime value
- Recency (days since last purchase)
- Segmentation RFM

### Produits
- Total revenue, quantity sold
- Average price, price range
- Unique customers
- Top countries per product

### GÃ©ographie
- Revenue by country
- Market share
- Average order value by country
- Customers per country

### Temporel
- Daily/weekly/monthly revenue
- Growth rates (%)
- Moving averages
- Trends and seasonality

## ğŸ¯ Cas d'usage

### Marketing
- Identifier les clients Ã  risque (high-value + inactifs)
- Segmentation pour campagnes ciblÃ©es
- Analyse de la rÃ©tention

### Finance
- Reporting mensuel automatique
- PrÃ©visions basÃ©es sur tendances
- Analyse de croissance

### Produit
- Optimisation du catalogue
- StratÃ©gie pricing
- Analyse cross-sell

### OpÃ©rations
- Monitoring quotidien
- DÃ©tection d'anomalies
- Planification de capacitÃ©

## ğŸ”§ Configuration

### Variables d'environnement (.env)

```bash
# MinIO
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_SECURE=False

# Prefect
PREFECT_API_URL=http://localhost:4200/api

# Database
SQLITE_DB_PATH=./data/database/analytics.db
```

## ğŸ“š Documentation

- `GOLD_LAYER.md`: Documentation dÃ©taillÃ©e de la couche Gold
- Voir les docstrings dans chaque fichier Python

## ğŸ› Troubleshooting

### MinIO ne dÃ©marre pas
```bash
docker-compose down
docker-compose up -d minio
```

### Prefect ne se connecte pas
```bash
# VÃ©rifier l'URL
echo $PREFECT_API_URL
# Devrait Ãªtre: http://localhost:4200/api
```

### Dashboard ne charge pas les donnÃ©es
```bash
# VÃ©rifier que le pipeline a Ã©tÃ© exÃ©cutÃ©
cd flows
python run_pipeline.py

# VÃ©rifier les buckets MinIO
# Aller sur http://localhost:9001
```

### Erreur de dÃ©pendances
```bash
# RÃ©installer
uv sync --reinstall
```

## ğŸ“ Prochaines Ã©tapes

1. **Ajouter des mÃ©triques avancÃ©es**
   - CLV prÃ©dictif
   - ProbabilitÃ© de churn
   - Cohort analysis

2. **Automatiser les rapports**
   - Scheduling quotidien/hebdomadaire
   - Envoi d'emails avec KPIs
   - Alertes sur anomalies

3. **Connecter un outil BI**
   - Metabase, Superset, ou Tableau
   - Dashboards partagÃ©s
   - Rapports automatiques

4. **Optimisations**
   - Utiliser Parquet au lieu de CSV
   - Partitionnement par date
   - Traitement incrÃ©mental

## ğŸ“ License

MIT

## ğŸ‘¥ Auteur

Projet de cours - Data Lake Architecture
